name: MBFA Build & Benchmark

on:
  push:
    branches: [ master, main, develop ]
  pull_request:
    branches: [ master, main ]
  workflow_dispatch:

permissions:
  contents: write
  actions: read

jobs:
  parse-commit:
    runs-on: ubuntu-latest
    outputs:
      should_publish: ${{ steps.check.outputs.should_publish }}
    steps:
      - name: Check for publish flag
        id: check
        run: |
          SHOULD_PUBLISH="false"
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            SHOULD_PUBLISH="true"
          else
            COMMIT_MSG="${{ github.event.head_commit.message }}"
            if echo "$COMMIT_MSG" | grep -qiE '\-\-(publish|deploy)'; then
              SHOULD_PUBLISH="true"
            fi
          fi
          echo "should_publish=${SHOULD_PUBLISH}" >> $GITHUB_OUTPUT
          echo "Will publish results: ${SHOULD_PUBLISH}"

  build-and-test:
    runs-on: ${{ matrix.os }}
    needs: parse-commit
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        rust: [stable]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ matrix.rust }}
          components: rustfmt, clippy

      - name: Cache Cargo
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

      - name: Check Formatting
        run: cargo fmt -- --check || true

      - name: Clippy
        run: cargo clippy --all-targets --all-features -- -D warnings 2>&1 | tee clippy-${{ matrix.os }}.txt || true

      - name: Build Debug
        run: cargo build --verbose 2>&1 | tee build-debug-${{ matrix.os }}.txt

      - name: Build Release
        run: cargo build --release --verbose 2>&1 | tee build-release-${{ matrix.os }}.txt

      - name: Run Tests
        run: cargo test --verbose 2>&1 | tee test-${{ matrix.os }}.txt

      - name: Upload build logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: build-logs-${{ matrix.os }}-${{ github.run_number }}
          path: "*.txt"
          retention-days: 30

  update-structure:
    runs-on: ubuntu-latest
    needs: [parse-commit, build-and-test]
    if: needs.parse-commit.outputs.should_publish == 'true'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Update ProjectStructure.txt
        run: |
          mkdir -p others
          {
            echo "Project Structure — MidMans Bit Folding Algorithm (MBFA)"
            echo "MidManStudio"
            echo "Generated: $(date -u)"
            echo "Repository: ${{ github.repository }}"
            echo "Commit: ${{ github.sha }}"
            echo "Branch: ${{ github.ref_name }}"
            echo "Build: #${{ github.run_number }}"
            echo "=================================="
            echo
            echo "Source Files:"
            find src -type f -name "*.rs" | sort
            echo
            echo "Bench Files:"
            find benches -type f -name "*.rs" 2>/dev/null | sort || echo "None"
            echo
            echo "Config:"
            ls -1 *.toml *.md 2>/dev/null | sort
            echo
            echo "Counts:"
            echo "  src: $(find src -type f -name '*.rs' | wc -l) files"
            echo "  benches: $(find benches -type f -name '*.rs' 2>/dev/null | wc -l || echo 0) files"
          } > others/ProjectStructure.txt
          cat others/ProjectStructure.txt

      - name: Commit structure update
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "MBFA CI"
          git add others/ProjectStructure.txt
          git diff --staged --quiet || git commit -m "Auto-update project structure — Build #${{ github.run_number }} [skip ci]"
          git push || true

  benchmark:
    runs-on: ubuntu-latest
    needs: [parse-commit, build-and-test]
    if: needs.parse-commit.outputs.should_publish == 'true'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: stable

      - name: Cache Cargo
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ubuntu-latest-cargo-${{ hashFiles('**/Cargo.lock') }}

      - name: Install tools
        run: sudo apt-get install -y gzip zstd xz-utils zpaq brotli bc

      - name: Build Release
        run: cargo build --release

      - name: Prepare benchmark files
        run: |
          mkdir -p bench_files bench_results

          # ── Small / medium (existing) ────────────────────────────────────────

          python3 -c "print('the the the and the and ' * 500)" > bench_files/repetitive.txt
          python3 -c "import os; open('bench_files/random.bin','wb').write(os.urandom(10000))"
          cp src/encoder.rs bench_files/source_code.rs
          curl -s -o bench_files/alice.txt "https://www.gutenberg.org/files/11/11-0.txt" || \
            python3 -c "print('the quick brown fox ' * 5000)" > bench_files/alice.txt
          head -c 20000  bench_files/alice.txt > bench_files/alice_small.txt
          head -c 100000 bench_files/alice.txt > bench_files/alice_100k.txt

          # JSON — realistic nested records (~100KB)
          python3 -c "
          import json, random
          random.seed(42)
          names  = ['alice','bob','charlie','diana','eve','frank','grace','henry']
          cities = ['london','paris','berlin','tokyo','sydney','cairo','oslo','lima']
          records = []
          for i in range(500):
              records.append({
                  'id': i, 'name': random.choice(names),
                  'email': f'user{i}@example.com', 'city': random.choice(cities),
                  'score': round(random.uniform(0,100),2),
                  'active': random.choice([True,False]),
                  'tags': random.sample(['admin','user','guest','mod'],2)
              })
          open('bench_files/data.json','w').write(json.dumps({'records':records},indent=2))
          "

          # WAV audio — synthetic tones, raw uncompressed PCM (~44KB)
          python3 -c "
          import struct, math
          sr = 44100; dur = 0.5; n = int(sr * dur)
          pcm = [int((math.sin(2*math.pi*440*i/sr)*0.5 +
                      math.sin(2*math.pi*880*i/sr)*0.3 +
                      math.sin(2*math.pi*220*i/sr)*0.2) * 32767) for i in range(n)]
          pcm_bytes = struct.pack(f'<{n}h', *pcm)
          fmt  = b'fmt ' + struct.pack('<IHHIIHH', 16, 1, 1, sr, sr*2, 2, 16)
          data = b'data' + struct.pack('<I', len(pcm_bytes)) + pcm_bytes
          body = b'WAVE' + fmt + data
          open('bench_files/audio.wav','wb').write(b'RIFF' + struct.pack('<I', len(body)) + body)
          "

          # BMP image — 100x100 gradient (~29KB)
          python3 -c "
          import struct
          w, h = 100, 100; pad = (4 - (w*3) % 4) % 4; px_sz = (w*3 + pad) * h
          hdr = (b'BM' + struct.pack('<I', 54+px_sz) + struct.pack('<HH',0,0) +
                 struct.pack('<I', 54) + struct.pack('<IiiHHIIiiII',40,w,h,1,24,0,px_sz,2835,2835,0,0))
          rows = []
          for y in range(h):
              row = b''
              for x in range(w):
                  row += bytes([int(x/w*255), int(y/h*255), int((x+y)/(w+h)*255)])
              rows.append(row + b'\x00'*pad)
          open('bench_files/image.bmp','wb').write(hdr + b''.join(reversed(rows)))
          "

          # ── Large (MB scale) ─────────────────────────────────────────────────

          # Large prose — War and Peace (~3.3 MB)
          echo "Downloading War and Peace..."
          if curl -fsSL --retry 3 --max-time 60 \
              "https://www.gutenberg.org/files/2600/2600-0.txt" \
              -o bench_files/prose_3mb.txt 2>/dev/null; then
            echo "War and Peace: $(wc -c < bench_files/prose_3mb.txt) bytes"
          else
            echo "Fallback: generating large prose file..."
            cat bench_files/alice.txt bench_files/alice.txt bench_files/alice.txt \
                bench_files/alice.txt bench_files/alice.txt bench_files/alice.txt \
                bench_files/alice.txt bench_files/alice.txt > bench_files/prose_3mb.txt
          fi

          # Large repetitive — 2MB structured repeating pattern
          python3 -c "
          unit = ('the the the and the and the cat sat on the mat and the rat was fat ' * 8 +
                  'hello world foo bar baz qux the end and the beginning ' * 4)
          target = 2 * 1024 * 1024
          out = (unit * (target // len(unit) + 1))[:target]
          open('bench_files/repetitive_2mb.txt', 'w').write(out)
          "

          # Large JSON — 2MB of realistic nested records
          python3 -c "
          import json, random
          random.seed(99)
          names    = ['alice','bob','charlie','diana','eve','frank','grace','henry',
                      'ivan','julia','karl','lena','mike','nina','oscar','paula']
          cities   = ['london','paris','berlin','tokyo','sydney','cairo','oslo','lima',
                      'moscow','delhi','chicago','dubai','seoul','toronto','madrid','rome']
          products = ['widget','gadget','doohickey','thingamajig','whatsit','gizmo',
                      'contraption','device','apparatus','mechanism']
          records = []
          for i in range(8000):
              records.append({
                  'id': i, 'name': random.choice(names),
                  'email': f'user{i}@example.com', 'city': random.choice(cities),
                  'country': random.choice(['US','UK','DE','JP','AU','FR','CA','BR']),
                  'score': round(random.uniform(0,100), 2),
                  'rank': random.randint(1, 1000),
                  'active': random.choice([True, False]),
                  'product': random.choice(products),
                  'quantity': random.randint(1, 500),
                  'tags': random.sample(['admin','user','guest','mod','viewer','editor'], 2),
                  'notes': f'Record {i} created automatically for benchmark testing purposes'
              })
          open('bench_files/data_2mb.json','w').write(json.dumps({'version':1,'records':records},indent=2))
          "

          # Large source — concatenate all Rust source files, repeat to ~1MB
          # NOTE: if src/*.rs total > 65KB, repetition period exceeds old 32KB window.
          # With OFFSET_BITS=17 (128KB window) this should now compress much better.
          cat src/*.rs > /tmp/all_src_once.rs
          SRC_BYTES=$(wc -c < /tmp/all_src_once.rs)
          echo "Source bundle size: ${SRC_BYTES} bytes (window is $((131071)) bytes)"
          python3 -c "
          src = open('/tmp/all_src_once.rs').read()
          target = 1048576
          out = (src * (target // len(src) + 1))[:target]
          open('bench_files/source_1mb.rs','w').write(out)
          "

          echo ""
          echo "All benchmark files:"
          ls -lh bench_files/
          echo ""
          echo "Source bundle vs window:"
          echo "  src/*.rs bundle: ${SRC_BYTES} bytes"
          echo "  OFFSET_BITS=17 window: 131071 bytes"
          if [ "$SRC_BYTES" -gt 131071 ]; then
            echo "  ⚠ WARNING: source bundle still exceeds window — expect partial cross-repetition matching"
          elif [ "$SRC_BYTES" -gt 65535 ]; then
            echo "  Window covers ~2 repetitions — moderate cross-rep matching"
          else
            echo "  ✓ Window comfortably covers multiple repetitions"
          fi

      - name: Roundtrip verification
        run: |
          echo "the the the and the and the and the cat sat on the mat" > bench_files/roundtrip_test.txt
          ./target/release/mbfa compress bench_files/roundtrip_test.txt bench_files/roundtrip_test.mbfa
          ./target/release/mbfa decompress bench_files/roundtrip_test.mbfa bench_files/roundtrip_recovered.txt
          if diff bench_files/roundtrip_test.txt bench_files/roundtrip_recovered.txt > /dev/null 2>&1; then
            echo "ROUNDTRIP: PASSED"
          else
            echo "ROUNDTRIP: FAILED"
            exit 1
          fi

      - name: Run benchmarks
        run: |
          fix_pct() { echo "$1" | sed 's/^\./0./'; }

          echo "[" > bench_results/results.json
          FIRST=true

          run_bench() {
            local file=$1
            local name=$2
            local orig_size=$(wc -c < "bench_files/$file")

            # ── MBFA ──────────────────────────────────────────────────────────
            local mbfa_start=$(date +%s%N)
            ./target/release/mbfa compress "bench_files/$file" "bench_files/$file.mbfa" \
              > bench_results/mbfa_log_${name}.txt 2>&1
            local mbfa_end=$(date +%s%N)
            local mbfa_ms=$(( (mbfa_end - mbfa_start) / 1000000 ))
            local mbfa_size=$(wc -c < "bench_files/$file.mbfa" 2>/dev/null || echo 0)

            local fold_detail=$(cat bench_results/mbfa_log_${name}.txt | \
              grep -E "^(Original|Fold|Done|Joint|Entropy|Window)" | \
              tr '\n' '|' | sed 's/"/\\"/g')

            ./target/release/mbfa decompress "bench_files/$file.mbfa" "bench_files/$file.recovered" \
              > /dev/null 2>&1
            local roundtrip="PASS"
            if ! diff "bench_files/$file" "bench_files/$file.recovered" > /dev/null 2>&1; then
              roundtrip="FAIL"
            fi

            # ── gzip ──────────────────────────────────────────────────────────
            local gz_start=$(date +%s%N)
            gzip -k -f "bench_files/$file" 2>/dev/null
            local gz_end=$(date +%s%N)
            local gz_ms=$(( (gz_end - gz_start) / 1000000 ))
            local gz_size=$(wc -c < "bench_files/$file.gz" 2>/dev/null || echo 0)

            # ── zstd ──────────────────────────────────────────────────────────
            local zst_start=$(date +%s%N)
            zstd -q -f "bench_files/$file" -o "bench_files/$file.zst" 2>/dev/null
            local zst_end=$(date +%s%N)
            local zst_ms=$(( (zst_end - zst_start) / 1000000 ))
            local zst_size=$(wc -c < "bench_files/$file.zst" 2>/dev/null || echo 0)

            # ── xz (lzma) ─────────────────────────────────────────────────────
            local xz_start=$(date +%s%N)
            xz -k -f "bench_files/$file" 2>/dev/null
            local xz_end=$(date +%s%N)
            local xz_ms=$(( (xz_end - xz_start) / 1000000 ))
            local xz_size=$(wc -c < "bench_files/$file.xz" 2>/dev/null || echo 0)

            # ── brotli ────────────────────────────────────────────────────────
            local br_start=$(date +%s%N)
            brotli -k -f "bench_files/$file" -o "bench_files/$file.br" 2>/dev/null
            local br_end=$(date +%s%N)
            local br_ms=$(( (br_end - br_start) / 1000000 ))
            local br_size=$(wc -c < "bench_files/$file.br" 2>/dev/null || echo 0)

            # ── zpaq ─────────────────────────────────────────────────────────
            local zpaq_start=$(date +%s%N)
            zpaq a "bench_files/$file.zpaq" "bench_files/$file" -method 2 > /dev/null 2>&1 || true
            local zpaq_end=$(date +%s%N)
            local zpaq_ms=$(( (zpaq_end - zpaq_start) / 1000000 ))
            local zpaq_size=$(wc -c < "bench_files/$file.zpaq" 2>/dev/null || echo 0)

            # ── percentages ───────────────────────────────────────────────────
            local mbfa_pct=$(fix_pct $(echo "scale=2; $mbfa_size * 100 / $orig_size" | bc))
            local gz_pct=$(fix_pct   $(echo "scale=2; $gz_size   * 100 / $orig_size" | bc))
            local zst_pct=$(fix_pct  $(echo "scale=2; $zst_size  * 100 / $orig_size" | bc))
            local xz_pct=$(fix_pct   $(echo "scale=2; $xz_size   * 100 / $orig_size" | bc))
            local br_pct=$(fix_pct   $(echo "scale=2; $br_size   * 100 / $orig_size" | bc))
            local zpaq_pct=$(fix_pct $(echo "scale=2; $zpaq_size * 100 / $orig_size" | bc))

            if [ "$FIRST" = "true" ]; then
              FIRST=false
            else
              echo "," >> bench_results/results.json
            fi

            cat >> bench_results/results.json << EOJSON
          {
            "dataset": "$name",
            "original_bytes": $orig_size,
            "mbfa_bytes": $mbfa_size,
            "mbfa_pct": $mbfa_pct,
            "mbfa_ms": $mbfa_ms,
            "mbfa_roundtrip": "$roundtrip",
            "gzip_bytes": $gz_size,
            "gzip_pct": $gz_pct,
            "gzip_ms": $gz_ms,
            "zstd_bytes": $zst_size,
            "zstd_pct": $zst_pct,
            "zstd_ms": $zst_ms,
            "xz_bytes": $xz_size,
            "xz_pct": $xz_pct,
            "xz_ms": $xz_ms,
            "brotli_bytes": $br_size,
            "brotli_pct": $br_pct,
            "brotli_ms": $br_ms,
            "zpaq_bytes": $zpaq_size,
            "zpaq_pct": $zpaq_pct,
            "zpaq_ms": $zpaq_ms,
            "fold_detail": "$fold_detail"
          }
          EOJSON

            printf "%-26s %9s B | MBFA:%6s%%(%sms) gz:%6s%% zst:%6s%% xz:%6s%% br:%6s%% zpaq:%6s%% rt:%s\n" \
              "$name" "$orig_size" \
              "$mbfa_pct" "$mbfa_ms" \
              "$gz_pct" "$zst_pct" "$xz_pct" "$br_pct" "$zpaq_pct" \
              "$roundtrip"
          }

          echo "================================================================"
          echo "  MidMans Bit Folding Algorithm — Extended Benchmark"
          echo "  Build #${{ github.run_number }} | $(date -u)"
          echo "  OFFSET_BITS=17 (128KB window) | fold 2 LZ gate: <10% ratio"
          echo "================================================================"
          echo ""
          echo "── Small / Medium ───────────────────────────────────────────────"
          run_bench "repetitive.txt"  "Repetitive_12KB"
          run_bench "alice_small.txt" "Prose_Alice_20KB"
          run_bench "alice_100k.txt"  "Prose_Alice_100KB"
          run_bench "random.bin"      "Random_10KB"
          run_bench "source_code.rs"  "Source_Code"
          run_bench "data.json"       "JSON_100KB"
          run_bench "audio.wav"       "Audio_WAV_44KB"
          run_bench "image.bmp"       "Image_BMP_29KB"
          echo ""
          echo "── Large (MB scale) ─────────────────────────────────────────────"
          run_bench "prose_3mb.txt"      "Prose_WarAndPeace_3MB"
          run_bench "repetitive_2mb.txt" "Repetitive_2MB"
          run_bench "data_2mb.json"      "JSON_2MB"
          run_bench "source_1mb.rs"      "Source_1MB"

          echo "]" >> bench_results/results.json

          echo ""
          echo "================================================================"
          echo "Lower % = better. rt = roundtrip."
          echo ""
          echo "Window diagnostic summary:"
          grep "Window diagnostics" bench_results/mbfa_log_*.txt | \
            sed 's/bench_results\/mbfa_log_//;s/\.txt:/: /' || true
          cat bench_results/results.json

      - name: Generate HTML report
        run: |
          BUILD_DATE=$(date -u)
          BUILD_NUM="${{ github.run_number }}"
          COMMIT="${{ github.sha }}"
          BRANCH="${{ github.ref_name }}"

          cp .github/benchmark-template.html bench_results/index.html

          sed -i "s/BUILD_NUM_PLACEHOLDER/${BUILD_NUM}/g"  bench_results/index.html
          sed -i "s/BRANCH_PLACEHOLDER/${BRANCH}/g"        bench_results/index.html
          sed -i "s/COMMIT_PLACEHOLDER/${COMMIT:0:8}/g"    bench_results/index.html
          sed -i "s|DATE_PLACEHOLDER|${BUILD_DATE}|g"      bench_results/index.html

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.run_number }}
          path: bench_results/
          retention-days: 90

  deploy-report:
    runs-on: ubuntu-latest
    needs: [parse-commit, benchmark]
    if: needs.parse-commit.outputs.should_publish == 'true'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results-${{ github.run_number }}
          path: bench_results

      - name: Deploy to gh-pages
        run: |
          git config --global user.name "MBFA CI"
          git config --global user.email "ci@mbfa.dev"

          mkdir -p /tmp/gh-pages
          git worktree add /tmp/gh-pages gh-pages 2>/dev/null || {
            cd /tmp/gh-pages && git init && git checkout --orphan gh-pages && cd -
          }

          mkdir -p /tmp/gh-pages/builds/build_${{ github.run_number }}
          cp -r bench_results/* /tmp/gh-pages/builds/build_${{ github.run_number }}/
          cp -r bench_results/* /tmp/gh-pages/

          cd /tmp/gh-pages
          git add .
          git commit -m "MBFA benchmark — Build #${{ github.run_number }} [skip ci]" || true
          git push "https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git" gh-pages --force

          echo "Deployed to https://mid-d-man.github.io/mbfa/"

  summary:
    runs-on: ubuntu-latest
    needs: [parse-commit, build-and-test]
    if: always()
    steps:
      - name: Print summary
        run: |
          echo "=================================="
          echo "  MBFA — MidMans Bit Folding Algorithm"
          echo "  MidManStudio"
          echo "=================================="
          echo "Build:     #${{ github.run_number }}"
          echo "Branch:    ${{ github.ref_name }}"
          echo "Published: ${{ needs.parse-commit.outputs.should_publish }}"
          echo ""
          echo "Use --publish or --deploy in commit message to run benchmarks."
